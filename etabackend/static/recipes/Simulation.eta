{"vi_templatejg59migx":"{\"nodes\":[{\"x\":101,\"y\":101,\"fixed\":true,\"text\":\"a\",\"px\":101,\"py\":101,\"initial\":true}],\"edges\":[{\"source\":0,\"target\":0,\"text\":\"10\"}],\"usercode\":\"a:\\n    emit(12,0)# here, ch1 is duplicated to ch3 with a delay of 0ps\"}","vi_templatejfc9koma":"{\"nodes\":[{\"x\":82,\"y\":88,\"fixed\":true,\"text\":\"a\",\"px\":82,\"py\":88,\"initial\":true}],\"edges\":[{\"source\":0,\"target\":0,\"text\":\"9\"}],\"usercode\":\"a:\\n    emit(11,0)# here, ch0 is duplicated to ch2 with a delay of 0ps\"}","eta_index_table":"[{\"id\":\"var_templatejkim8w21\",\"name\":\"binsize\",\"group\":\"main\",\"info\":\"\",\"config\":\"16\"},{\"id\":\"var_templatek5wr10m4\",\"name\":\"bins\",\"group\":\"main\",\"info\":\"\",\"config\":\"10000\"},{\"id\":\"var_templatejkim95ub\",\"name\":\"plotsize_x\",\"group\":\"main\",\"info\":\"\",\"config\":\"3200\"},{\"id\":\"var_templatejrvu8s5g\",\"name\":\"analyze_timewindow\",\"group\":\"main\",\"info\":\"\",\"config\":\"True\"},{\"id\":\"var_templatek5wr3vjc\",\"name\":\"runtime\",\"group\":\"main\",\"info\":\"\",\"config\":\"48000\"},{\"id\":\"var_templatek627u266\",\"name\":\"ETA_VERSION\",\"group\":\"main\",\"info\":\"\",\"config\":\"0.7.2\"},{\"id\":\"var_templatek8oniclt\",\"name\":\"savefile\",\"group\":\"main\",\"info\":\"\",\"config\":\"C:/YourFolder/YourFile.csv\"},{\"id\":\"var_templatek8otc7cm\",\"name\":\"generation_efficiency\",\"group\":\"main\",\"info\":\"\",\"config\":\"1\"},{\"id\":\"var_templatek8otdk2b\",\"name\":\"detection_efficiency_XX\",\"group\":\"main\",\"info\":\"\",\"config\":\"1\"},{\"id\":\"var_templatek8otdo36\",\"name\":\"detection_efficiency_X\",\"group\":\"main\",\"info\":\"\",\"config\":\"1\"},{\"id\":\"dpp_templatek0e4fe69\",\"name\":\"display\",\"group\":\"main\",\"info\":\"\",\"config\":\"\"},{\"id\":\"dpp_templatek0e4ffk5\",\"name\":\"create txt\",\"group\":\"main\",\"info\":\"\",\"config\":\"\"},{\"id\":\"dpp_templatejgs3h609\",\"name\":\"txt 2 graph (zoom-in)\",\"group\":\"main\",\"info\":\"\",\"config\":\"\"},{\"id\":\"dpp_templatejgs1c21d\",\"name\":\"txt 2 g2 analysis and graph\",\"group\":\"main\",\"info\":\"\",\"config\":\"\"},{\"id\":\"vi_templatek5wjc5eo\",\"name\":\"sync generator\",\"group\":\"main\",\"info\":\"📤[0] \",\"config\":\"\"},{\"id\":\"vi_templatek8oikos6\",\"name\":\"generation losses\",\"group\":\"main\",\"info\":\"📥[0] 📤[1, 2] \",\"config\":\"\"},{\"id\":\"vi_templatek5wjumx9\",\"name\":\"QD\",\"group\":\"main\",\"info\":\"📥[1, 3, 4] 📤[3, 4] \",\"config\":\"\"},{\"id\":\"vi_templatek8oikwhw\",\"name\":\"detection losses XX\",\"group\":\"main\",\"info\":\"📥[3] 📤[5, 6] \",\"config\":\"\"},{\"id\":\"vi_templatek8oize34\",\"name\":\"detection losses X\",\"group\":\"main\",\"info\":\"📥[4] 📤[7, 8] \",\"config\":\"\"},{\"id\":\"vi_templatek8oid9rt\",\"name\":\"X-XX splitter (alternative to beam splitter)\",\"group\":\"main\",\"info\":\"📥[5, 7] 📤[9, 10] \",\"config\":\"\"},{\"id\":\"vi_templatek5wotz9c\",\"name\":\"beam splitter (alternative to X-XX splitter)\",\"group\":\"disabled\",\"info\":\"📥[5, 7] 📤[9, 10] \",\"config\":\"\"},{\"id\":\"vi_templatejfc9koma\",\"name\":\"DL9-11\",\"group\":\"main\",\"info\":\"📥[9] 📤[11] \",\"config\":\"\"},{\"id\":\"vi_templatejg59migx\",\"name\":\"DL10-12\",\"group\":\"main\",\"info\":\"📥[10] 📤[12] \",\"config\":\"\"},{\"id\":\"vi_templatek0e3qybt\",\"name\":\"Correlationbwd\",\"group\":\"main\",\"info\":\"📥[11, 12] \",\"config\":\"\"},{\"id\":\"vi_templatek0e3sowi\",\"name\":\"Correlationfwd\",\"group\":\"main\",\"info\":\"📥[12, 11] \",\"config\":\"\"}]","dpp_templatejgs1c21d":"#------IMPORTS-----\r\nfrom pathlib import Path\r\n\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\nimport matplotlib.pyplot as plt\r\n\r\ndef get_files(extensions):\r\n    global path, datafolder\r\n    path=path.joinpath(datafolder)\r\n    all_files = []\r\n    for ext in extensions:\r\n        all_files.extend(path.glob(ext))\r\n    return all_files\r\n\r\nanalyze_timewindow = bool(analyze_timewindow)\r\n\r\n#------ETA PROCESSING-----\r\ndatafolder='analyzed data'\r\ngraphsfolder='graphs'\r\npath = Path(file)\r\n\r\nif path.is_dir():\r\n    selector = get_files(('*.txt',))\r\nelse:\r\n    if path.suffix == '.txt':\r\n        selector = [path]\r\n    else:\r\n        selector = [path.parent.joinpath(datafolder, path.stem + '_correlation' + '.txt')]\r\n\r\nfor f in selector:\r\n        list_of_title=f.stem.split('_')\r\n\r\n        data=pd.read_table(f, header=None, names=['ps', 'cnts'], sep=' ')\r\n        data.set_index('ps', inplace=True)\r\n        data = data['cnts']\r\n        \r\n        numberofsidepeaks = 8 # must be even\r\n        bin=16\r\n        shift = 0\r\n        widthofdata = 120000 #how the data is going to be cut. Allow enough ps to accomodate the numberofsidepeaks\r\n        leftend = int(-widthofdata/2+shift)\r\n        rightend = int(widthofdata/2+shift)\r\n        lessthanrep = 12300 #less than the laser repetition rate in ps\r\n        \r\n        reprate = int(((data.loc[rightend-lessthanrep:rightend].idxmax()-data.loc[leftend:leftend+lessthanrep].idxmax())/int(numberofsidepeaks)))\r\n        \r\n        g2vsdT = pd.DataFrame()\r\n        for window in range(bin, lessthanrep, bin):\r\n            peaks = np.array([])\r\n            \r\n            for x in range(int(data.loc[leftend:leftend+reprate].idxmax()), rightend, reprate):\r\n                temp0=data.loc[x-window/2:x+window/2].sum()\r\n                peaks=np.append([peaks], [temp0])\r\n        \r\n            center = peaks[int(numberofsidepeaks/2)]\r\n            average = np.mean([peaks[:int(numberofsidepeaks/2)], peaks[1+int(numberofsidepeaks/2):]])\r\n            average_err = (np.sqrt(np.sum([peaks[:int(numberofsidepeaks/2)], peaks[1+int(numberofsidepeaks/2):]]))/int(numberofsidepeaks))\r\n            g2 = center/average\r\n            g2_err = np.sqrt(center/(average**2)+(average_err**2)*(peaks[int(numberofsidepeaks/2)]**2)/average**4)\r\n            \r\n            if window == 1600:\r\n                print('Time window: '+str(window)+' ps'+'\\n'+'average counts per peak: '+str(average) + ' pm ' + str(average_err) + '\\n' + 'g2: '+ str(g2)+ ' pm ' + str(g2_err)+'\\n'+'center peak delay: ' + str(reprate*(numberofsidepeaks/2)+data.loc[leftend:leftend+lessthanrep].idxmax())+' ps' +'\\n'+'pulse delay: '+str(reprate)+' ps')\r\n                center_peak_delay = reprate*(numberofsidepeaks/2)+data.loc[leftend:leftend+lessthanrep].idxmax()\r\n                good_average = average\r\n                good_average_err = average_err\r\n                good_g2 = g2\r\n                good_g2_err = g2_err\r\n            temp1 = pd.DataFrame([[window, g2, g2_err]], columns=['Time Window', 'g(2)', 'delta g(2)'])\r\n            g2vsdT = pd.concat([g2vsdT, temp1], ignore_index=True)\r\n        \r\n        \r\n        g2vsdT.set_index('Time Window', inplace=True)\r\n        g2vsdT = pd.concat([g2vsdT, g2vsdT['g(2)']+g2vsdT['delta g(2)'], g2vsdT['g(2)']-g2vsdT['delta g(2)']], axis=1)\r\n        g2vsdT.rename(columns={0:'err+', 1:'err-'}, inplace=True)\r\n        \r\n        title='average counts per peak: '+str(int(good_average)) + r' $\\pm$ ' + str(int(good_average_err)) + '\\n' + 'g2: '+  \"{0:.6f}\".format(good_g2) + r' $\\pm$ ' + \"{0:.6f}\".format(good_g2_err)\r\n        data = data.loc[leftend:rightend]\r\n        p1 = plt.bar(data.index,data, width=bin, color='salmon', log=True)\r\n\r\n        plt.ylabel('correlation events')\r\n        plt.xlabel('time (ps)')\r\n        plt.title(title)\r\n        f.parent.parent.joinpath(graphsfolder).mkdir(parents=True, exist_ok=True)\r\n        plt.savefig(f.parent.parent.joinpath(graphsfolder, f.stem + '_analyzed' + '.eps'), format='eps', dpi=1200)\r\n        plt.savefig(f.parent.parent.joinpath(graphsfolder, f.stem + '_analyzed' + '.png'), format='png', dpi=1200)\r\n        plt.clf()\r\n        \r\n        if analyze_timewindow == True:\r\n            plt.plot(g2vsdT.index, g2vsdT['g(2)'], 'b')\r\n            plt.fill_between(g2vsdT.index, g2vsdT['err+'], g2vsdT['err-'], color='b', alpha=0.2)\r\n            plt.ylabel('g2(0)')\r\n            plt.xlabel('analysis window (ps)')\r\n            plt.savefig(f.parent.parent.joinpath(graphsfolder, f.stem + '_windows' + '.eps'), format='eps', dpi=1200)\r\n            plt.savefig(f.parent.parent.joinpath(graphsfolder, f.stem + '_windows' + '.png'), format='png', dpi=1200)\r\n            plt.clf()","dpp_templatejgs3h609":"#------IMPORTS-----\r\nfrom pathlib import Path\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\n\r\ndef get_files(extensions):\r\n    global path, datafolder\r\n    path=path.joinpath(datafolder)\r\n    all_files = []\r\n    for ext in extensions:\r\n        all_files.extend(path.glob(ext))\r\n    return all_files\r\n\r\n#------ETA PROCESSING-----\r\ngraphsfolder='graphs'\r\ndatafolder='analyzed data'\r\npath = Path(file)\r\n\r\nif path.is_dir():\r\n    selector = get_files(('*.txt',))\r\nelse:\r\n    if path.suffix == '.txt':\r\n        selector = [path]\r\n    else:\r\n        selector = [path.parent.joinpath(datafolder, path.stem + '_correlation' + '.txt')]\r\n\r\nplotsize_x=int(plotsize_x)\r\nbinsize=int(float(binsize))\r\n\r\nfor f in selector:\r\n        print(f.stem)\r\n        data=np.loadtxt(f)\r\n        read_bins=len(np.transpose(data)[0])\r\n        p1 = plt.bar(data[int((read_bins-plotsize_x/binsize)/2):int((read_bins+plotsize_x/binsize)/2),0], data[int((read_bins-plotsize_x/binsize)/2):int((read_bins+plotsize_x/binsize)/2),1],width=binsize, color='#0088ff')\r\n        plt.ylabel('events')\r\n        plt.xlabel('time (ps)')\r\n        f.parent.parent.joinpath(graphsfolder).mkdir(parents=True, exist_ok=True)\r\n        plt.savefig(f.parent.parent.joinpath(graphsfolder, f.stem + '_inset' + '.eps'), format='eps', dpi=1200)\r\n        plt.savefig(f.parent.parent.joinpath(graphsfolder, f.stem + '_inset' + '.png'), format='png', dpi=1200)\r\n        plt.clf()\r\n        eta.send(f.name + ' has been successfully plotted')","var_templatejkim8w21":null,"var_templatejkim95ub":null,"var_templatejrvu8s5g":null,"vi_templatek0e3qybt":"{\"nodes\":[{\"x\":346,\"y\":111,\"fixed\":true,\"text\":\"start\",\"px\":346,\"py\":111},{\"x\":75,\"y\":86,\"fixed\":true,\"text\":\"stop\",\"px\":75,\"py\":86,\"initial\":true}],\"edges\":[{\"source\":0,\"target\":1,\"text\":\"11\"},{\"source\":1,\"target\":0,\"text\":\"12\"},{\"source\":0,\"target\":0,\"text\":\"12\"},{\"source\":1,\"target\":1,\"text\":\"11\"}],\"usercode\":\"HISTOGRAM(h2,(`bins`,`binsize`,\\\"time-1\\\"))\\nHISTOGRAM(h2_zero,(1,1))\\nCLOCK(c2,100,1)\\nstart:\\n    c2.start()\\nstop:\\n    c2.stop()\\n    h2.record_all(c2)\\n    h2_zero.record_all(c2)\"}","vi_templatek0e3sowi":"{\"nodes\":[{\"x\":346,\"y\":111,\"fixed\":true,\"text\":\"start\",\"px\":346,\"py\":111},{\"x\":76,\"y\":88,\"fixed\":true,\"text\":\"stop\",\"px\":76,\"py\":88,\"initial\":true}],\"edges\":[{\"source\":0,\"target\":1,\"text\":\"12\"},{\"source\":1,\"target\":0,\"text\":\"11\"},{\"source\":0,\"target\":0,\"text\":\"11\"},{\"source\":1,\"target\":1,\"text\":\"12\"}],\"usercode\":\"HISTOGRAM(h1,(`bins`,`binsize`))\\nCLOCK(c1,100,1)\\nstart:\\n    c1.start()\\nstop:\\n    c1.stop()\\n    h1.record_all(c1)\"}","dpp_templatek0e4fe69":"#------IMPORTS-----\r\n\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom pathlib import Path\r\nfrom bokeh.layouts import column\r\nfrom bokeh.models import ColumnDataSource, Slider\r\nfrom bokeh.models.tools import HoverTool\r\nfrom bokeh.plotting import figure\r\nfrom bokeh.server.server import Server\r\nfrom bokeh.themes import Theme\r\n\r\n\r\n#------ETA PROCESSING-----\r\n\r\nresult= eta.run(None, group='main', stop_with_source=False)\r\nhist1=result[\"h1\"]\r\nhist2=result[\"h2\"]\r\nhist0=result[\"h2_zero\"]\r\nhist1[0]+= hist0[0]\r\n\r\nfullhist=np.concatenate((hist2[::-1],hist1))\r\nxdata = np.arange(-hist2.size,hist1.size)*int(float(binsize))\r\n\r\n#------PLOTTING-----\r\n\r\ndf = pd.DataFrame(np.vstack((xdata, fullhist)).T, \r\n                  columns=['time bins', 'histogram events'])\r\ndf['zero'] = int(len(df['time bins'].values))*[0]\r\n\r\ndef generate_doc(doc):\r\n    source = ColumnDataSource(df)\r\n\r\n    def style(p):\r\n        from bokeh.models import Range1d\r\n        # Title \r\n        p.title.align = 'center'\r\n        p.title.text_font_size = '20pt'\r\n        p.title.text_font = 'serif'\r\n\r\n        # Axis titles\r\n        p.xaxis.axis_label_text_font_size = '14pt'\r\n        p.xaxis.axis_label_text_font_style = 'bold'\r\n        p.yaxis.axis_label_text_font_size = '14pt'\r\n        p.yaxis.axis_label_text_font_style = 'bold'\r\n\r\n        # Tick labels\r\n        p.xaxis.major_label_text_font_size = '12pt'\r\n        p.yaxis.major_label_text_font_size = '12pt'\r\n        \r\n        # limit data range\r\n        p.x_range = Range1d(-hist2.size*int(float(binsize)), hist1.size*int(float(binsize)))\r\n        p.y_range = Range1d(0, df['histogram events'].max(axis=0)*1.1)\r\n        \r\n        # remove padding\r\n        p.min_border_bottom = 0\r\n        p.min_border_left = 0\r\n        \r\n        # legend\r\n        p.legend.location = \"top_right\"\r\n        p.legend.click_policy=\"hide\"\r\n        \r\n        return p\r\n\r\n\r\n\r\n    def make_plot(src):\r\n        hover=HoverTool(tooltips = [\r\n                    (\"Delay: \", \"@{time bins}\"),\r\n                    (\"Histogram events: \", \"@{histogram events}\"),\r\n                    ],\r\n                    mode='vline', point_policy = \"snap_to_data\",\r\n                    line_policy = \"nearest\"\r\n                )\r\n        toolbox = \"pan,wheel_zoom,box_zoom,reset\"\r\n        # Blank plot with correct labels\r\n        p = figure(plot_width = 700, plot_height = 700, tools=toolbox,\r\n                  #active_drag=\"box_zoom\",\r\n                  active_scroll='wheel_zoom',\r\n                  title = 'Correlation',\r\n                  x_axis_label = 'Time delay (ps)',\r\n                  y_axis_label = 'Histogram events')\r\n        p.add_tools(hover)\r\n        \r\n        p.line(x='time bins', y='histogram events', \r\n                source=src, color='firebrick', legend_label='Correlation', line_width=1.5\r\n                )\r\n\r\n        # Styling\r\n        p = style(p)\r\n        return p\r\n\r\n    p = make_plot(source)\r\n    doc.add_root(column(p, sizing_mode='stretch_both'))\r\n    \r\n    return doc\r\n\r\neta.display(generate_doc, 'bokeh')","dpp_templatek0e4ffk5":"#------IMPORTS-----\r\nfrom pathlib import Path\r\nimport numpy as np\r\n\r\ndef info(filename, binsize=binsize, bins=bins):\r\n    return (f'Analyzed with ETA - github.com/timetag\\n'\r\n            f'filename: {filename.name}\\n'\r\n            f'binsize: {binsize}\\n'\r\n            f'bins: {bins}\\n'\r\n            )\r\n\r\n#------ETA PROCESSING-----\r\nbinsize=int(float(binsize))\r\nf=Path(savefile)\r\n\r\nresult=eta.run(None, group='main')\r\nhist1=result[\"h1\"]\r\nhist2=result[\"h2\"]\r\nhist0=result[\"h2_zero\"]\r\nhist1[0]+= hist0[0]\r\n\r\nfullhist=np.concatenate((hist2[::-1],hist1))\r\nf.parent.mkdir(parents=True, exist_ok=True)\r\nnp.savetxt(f.parent.joinpath(f.stem + '.txt'), np.transpose([np.arange(-hist2.size,hist1.size)*binsize,fullhist]), delimiter='\\t', header=info(f))\r\neta.send(str(f.name) + ' has been successfully processed')\r\neta.send('FINISHED')","vi_templatek5wjc5eo":"{\"nodes\":[{\"x\":225,\"y\":95,\"fixed\":true,\"initial\":true,\"text\":\"a\",\"px\":225,\"py\":95}],\"edges\":[],\"usercode\":\"emit(0, 0, 12500, `runtime`)\"}","vi_templatek5wjumx9":"{\"nodes\":[{\"x\":132,\"y\":338,\"fixed\":true,\"text\":\"g\",\"initial\":true,\"px\":132,\"py\":338},{\"x\":134,\"y\":65,\"weight\":1,\"fixed\":true,\"text\":\"XX\",\"px\":134,\"py\":65},{\"x\":187,\"y\":213,\"weight\":1,\"fixed\":true,\"px\":187,\"py\":213,\"text\":\"X\"}],\"edges\":[{\"source\":0,\"target\":1,\"text\":\"1\"},{\"source\":1,\"target\":2,\"text\":\"3\"},{\"source\":2,\"target\":0,\"text\":\"4\"}],\"usercode\":\"INTEGER(xx_delay)\\nINTEGER(x_delay)\\n\\nXX:\\n    {\\n        binsize = 16\\n        xx_delay_arr = ((np.random.exponential(125, 1))/binsize)\\n        xx_delay = round(xx_delay_arr[0])*binsize\\n    }\\n    emit(3,xx_delay)\\n\\nX:\\n    {\\n        binsize = 16\\n        x_delay_arr = ((np.random.exponential(250, 1))/binsize)\\n        x_delay = round(x_delay_arr[0])*binsize\\n    }\\n    emit(4,x_delay)\"}","vi_templatek5wotz9c":"{\"nodes\":[{\"x\":137,\"y\":114,\"fixed\":true,\"initial\":true,\"text\":\"a\",\"px\":137,\"py\":114}],\"edges\":[{\"source\":0,\"target\":0,\"text\":\"5,7\"}],\"usercode\":\"VFILE(9)\\nVFILE(10)\\n\\nINTEGER(retchn)\\na--5-->a:\\n{\\n        options = np.asarray([9,10])\\n        retchn = np.random.choice(options)\\n}\\nemit(retchn,0)\\n\"}","var_templatek5wr10m4":null,"var_templatek5wr3vjc":null,"var_templatek627u266":null,"vi_templatek8oid9rt":"{\"nodes\":[{\"x\":137,\"y\":114,\"fixed\":true,\"initial\":true,\"text\":\"a\",\"px\":137,\"py\":114}],\"edges\":[{\"source\":0,\"target\":0,\"text\":\"5,7\"}],\"usercode\":\"VFILE(9)\\nVFILE(10)\\n\\na--5-->a:\\n    emit(9,0)\\n\\na--7-->a:\\n    emit(10,0)\"}","vi_templatek8oikos6":"{\"nodes\":[{\"x\":215,\"y\":133,\"fixed\":true,\"initial\":true,\"text\":\"a\"}],\"edges\":[{\"source\":0,\"target\":0,\"text\":\"0\"}],\"usercode\":\"VFILE(1)\\nVFILE(2)\\nINTEGER(lossy_s)\\na:\\n    {   \\n        g_losses_s=1-`generation_efficiency`\\n        options1 = np.asarray([1,2])\\n        lossy_s = options1[np.searchsorted(np.cumsum(\\n            np.asarray([1-g_losses_s,g_losses_s])\\n            ), np.random.random(), side=\\\"right\\\")]\\n    }\\n    emit(lossy_s,0)\"}","vi_templatek8oikwhw":"{\"nodes\":[{\"x\":222,\"y\":100,\"fixed\":true,\"initial\":true,\"text\":\"a\"}],\"edges\":[{\"source\":0,\"target\":0,\"text\":\"3\"}],\"usercode\":\"VFILE(5)\\nVFILE(6)\\nINTEGER(lossy_xx)\\na:\\n    {\\n        d_losses_xx=1-`detection_efficiency_XX`\\n        options2 = np.asarray([5,6])\\n        lossy_xx = options2[np.searchsorted(np.cumsum(\\n            np.asarray([1-d_losses_xx,d_losses_xx])\\n            ), np.random.random(), side=\\\"right\\\")]\\n    }\\n    emit(lossy_xx,0)\"}","vi_templatek8oize34":"{\"nodes\":[{\"x\":222,\"y\":100,\"fixed\":true,\"initial\":true,\"text\":\"a\"}],\"edges\":[{\"source\":0,\"target\":0,\"text\":\"4\"}],\"usercode\":\"VFILE(7)\\nVFILE(8)\\nINTEGER(lossy_x)\\na:\\n    {\\n        d_losses_x = 1-`detection_efficiency_X`\\n        options3 = np.asarray([7,8])\\n        lossy_x = options3[np.searchsorted(\\n            np.cumsum(np.asarray([1-d_losses_x,d_losses_x])\\n            ), np.random.random(), side=\\\"right\\\")]\\n    }\\n    emit(lossy_x,0)\"}","var_templatek8oniclt":null,"var_templatek8otc7cm":null,"var_templatek8otdk2b":null,"var_templatek8otdo36":null}